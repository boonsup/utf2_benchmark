% =====================================================================
% Supplementary Section S2: Latency Scaling Benchmark
% =====================================================================

\clearpage
\section*{Supplementary Section S2: Latency Scaling Benchmark}

\noindent
This section provides a detailed analysis of the latency scaling performance
of the UTFv2 operators under varying simulation sizes and GPU configurations.
Benchmarking was conducted on NVIDIA~A100~(40\,GB) and RTX~4090~(24\,GB)
devices, using the same kernel version as in Section~S1.

The latency profile follows the model
\[
\tau_{\mathrm{total}} = \tau_0 + aN^{\gamma},
\]
where $\gamma$ is empirically determined from regression over
increasing parallelism levels ($N = 2^{8} \ldots 2^{16}$).

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{figures/supplementary_S2_latency_scaling.png}
    \caption{
        \textbf{S2. Latency--Parallelism Relationship.}
        Observed total latency $\tau_{\mathrm{total}}$ as a function of system
        parallelism $N$, compared with theoretical scaling fits for both CPU and
        GPU modes. The UTFv2 kernel exhibits near-ideal sublinear scaling up to
        $N \approx 2^{14}$.
    }
    \label{fig:s2_latency}
\end{figure}

\vspace{1em}
Table~\ref{tab:latency_summary} summarizes average latencies per operator.
All raw data are available in \texttt{data/supplementary\_S2\_latency.csv}.

% If booktabs is not available, use this simpler table:
\begin{table}[h!]
\centering
\caption{Mean kernel latency for each operator.}
\label{tab:latency_summary}
\begin{tabular}{lcc}
\hline
Operator & Mean Latency (ms) & Std.\ Dev. \\
\hline
$\hat{T}$ & 0.83 & 0.04 \\
$\hat{D}$ & 1.12 & 0.05 \\
$\hat{F}$ & 1.37 & 0.07 \\
\hline
\end{tabular}
\end{table}

